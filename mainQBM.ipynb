{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUANTUM BOLTZMANN MACHINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum Boltzmann Machine (QBM) is a machine learning approach based on quantum Boltzmann distribution and exploiting the rapid growth of the Hilbert space dimension to speed up the classical machine learning algorithm: the Boltzman Machine (BM), when implemented on a quantum hardware. \n",
    "\n",
    "In this small research project we try to replicate the results of the following paper: https://arxiv.org/abs/1601.02036. In particular, we focus on its first example (Section 4) of a fully visible model with N variables, this allows to confront the training of classical Boltzmann Machine, quantum Boltzmann Machine and another variant called bound-QBM. \n",
    "\n",
    "In the models, a state is associated with an energy function or Hamiltoninan. The goal is to learn the energy parameters b, w, gamma for each of the N variables (spin or qubit), so that the learned distribution of the data (Boltzmann distribution) is as similar as possible to the actual data distribution. The learning is achieved by finding the parameters that minimize the negative log-likelihood. The minimization is done by adjusting the parameters at each step in the opposite direction of the gradient (gradient descent technique). The step size is controlled by a fixed learning rate eta.\n",
    "\n",
    "All three algorithms are presented below, along with commentary and a final plot to compare the results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fully visible BM model, given N spin variables (binary units) that define a state, there are N + N(N-1)/2 trainable parameters: b(a) and w(a,b); gamma = 0 : there are no transverse components of spin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def energy(z, b, W):\n",
    "    \"\"\" \n",
    "    E(z) = - sum_a (b_a z_a) - sum_{a,b} (w_{a,b} z_a z_b)\n",
    "    for a single configuration z in {+1, -1}^N. \n",
    "    \"\"\"\n",
    "    # We'll compute this directly:\n",
    "    #   E(z) = - (b·z + z^T W z)\n",
    "    bz = np.dot(b, z)\n",
    "    zWz = np.dot(z, np.matmul(W, z))\n",
    "    return -(bz + zWz)\n",
    "\n",
    "def boltzmann_distribution(b, W, all_states):\n",
    "    \"\"\"\n",
    "    Enumerate all states z in {+1, -1}^N, compute\n",
    "        P_model(z) = exp[-E(z)] / Z\n",
    "    and return a (2^N,) probability vector.\n",
    "    \"\"\"\n",
    "    energies = []\n",
    "    for z in all_states:\n",
    "        E_z = energy(z, b, W)\n",
    "        energies.append(E_z)\n",
    "    energies = np.stack(energies)  # shape (2^N)\n",
    "\n",
    "    # exponentiate -E(z) already appears in 'energies' as negative\n",
    "    # but we have E_z = -(...) so actually we want exp(-E_z) = exp(+ ...).\n",
    "    # Let's just do exp(-E_z):\n",
    "    negE = -energies\n",
    "    exp_shifted = np.exp(negE)\n",
    "    Z = exp_shifted.sum()\n",
    "    return exp_shifted / Z\n",
    "\n",
    "# Kullback-Leibler (KL) divergence: KL = Likelihood - Likelihood_min\n",
    "def kl_divergence(P_data, P_model):\n",
    "    return np.sum(P_data * np.log((P_data + 1e-12)/(P_model + 1e-12)))\n",
    "\n",
    "# Define Parameters\n",
    "N = 8  # Number of visible spins z in {+1, -1}\n",
    "M = 8  # Number of modes for data distribution\n",
    "p = 0.9 # Spin alignment probability with mode centers\n",
    "eta = 0.2  # Learning rate\n",
    "num_steps = 35 # Number of optimization steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate parameter is chosen empirically as the one that enables the algorithm to obtain the lowest value of KL divergence, which quantifies the quality of training. The same approach has been applied to the bound-QBM and QBM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate M random center points s^k in {+1, -1}^N\n",
    "centers = np.random.randint(low=0, high=2, size=(M, N))  # in {0,1}\n",
    "centers = 2*centers - 1  # map to {+1,-1}\n",
    "\n",
    "# Enumerate all states z in {+1, -1}^N\n",
    "all_configs = list(itertools.product([-1, +1], repeat=N))\n",
    "all_z = np.array(all_configs, dtype=np.float32)  # (2^N, N)\n",
    "\n",
    "def mixture_data_distribution(all_states, centers, p):  \n",
    "    \"\"\"Generate training data as a mixture of M modes using \n",
    "        Bernouilli distribution: p^(N-d_kv)*(1-p)^d_kv \"\"\"\n",
    "    num_modes = centers.shape[0]  # The number of modes (M=8) is the centers' number of rows\n",
    "    N_ = centers.shape[1]         # The number of bits (N=10) is the centers' number of columns \n",
    "    N_states = all_states.shape[0] # (2^N)\n",
    "    probs = np.zeros(N_states, dtype=np.float32)\n",
    "    for s in range(N_states):  \n",
    "        mode_sum = 0.0\n",
    "        for k in range(num_modes): \n",
    "            d_ks = 0.5 * np.sum(1 - all_states[s, :] * centers[k, :])  # Hamming distance between state s and center k\n",
    "            mode_sum += p**(N_ - d_ks) * (1 - p)**d_ks  # mixture of Bernoulli distribution\n",
    "        probs[s] = mode_sum / num_modes   # Generating P_data for each state\n",
    "    # normalitation\n",
    "    probs /= probs.sum()\n",
    "    return probs\n",
    "\n",
    "P_data = mixture_data_distribution(all_z, centers, p)\n",
    "print(\"Check sum of P_data:\", P_data.sum().item())  # ~1.0\n",
    "print(\"Check dimension of P_data:\", P_data.shape)  # ~2^10 = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the BM fully visible model the gradient steps are expressed in terms of different avergaes called 'positive' and 'negative' phases. The positive and negative phases for each parameter are obtained by averaging the respective spin variable over the data distribution and the model distribution, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 'positive phase' averages once: <z_a>_data, <z_a z_b>_data for each a,b = 1,2,...,N\n",
    "z_data_avg = np.zeros(N)\n",
    "zz_data_avg = np.zeros((N, N))\n",
    "N_states = all_z.shape[0]\n",
    "for i in range(N_states):\n",
    "    z_data_avg += P_data[i] * all_z[i, :] \n",
    "    zz_data_avg += P_data[i] * np.outer(all_z[i, :], all_z[i, :])\n",
    "\n",
    "# Manual Gradient Updates Using exact formulas\n",
    "# Initialize parameters (b, W) using 'random.seed'\n",
    "np.random.seed(42)\n",
    "b = 0.01 * np.random.randn(N)\n",
    "W = 0.01 * np.random.randn(N, N)\n",
    "\n",
    "kl_history = []\n",
    "for step in range(num_steps):\n",
    "    # 1) Compute model distribution\n",
    "    P_model = boltzmann_distribution(b, W, all_z)\n",
    "    # 2) 'Negative phase' averages: <z_a>_model, <z_a z_b>_model for each a,b = 1,2,...,N\n",
    "    z_model_avg = np.zeros(N)\n",
    "    zz_model_avg = np.zeros((N, N))\n",
    "    for i in range(N_states):\n",
    "      z_model_avg += P_model[i] * all_z[i, :]\n",
    "      zz_model_avg += P_model[i] * np.outer(all_z[i, :], all_z[i, :])\n",
    "    \n",
    "    # Compute gradient steps as difference between positive and negative phases\n",
    "    db = eta * (z_data_avg - z_model_avg) \n",
    "    dW = eta * (zz_data_avg - zz_model_avg)\n",
    "\n",
    "    b += db\n",
    "    W += dW\n",
    "    \n",
    "    # Compute and save KL value\n",
    "    this_kl = kl_divergence(P_data, P_model)\n",
    "    kl_history.append(this_kl.item())\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        print(f\"Iter {step}: KL = {this_kl.item():.4f}\")\n",
    "\n",
    "# Saving Data frame in CSV\n",
    "df = pd.DataFrame({\"iteration\": list(range(num_steps)), \"kl_history\": kl_history})\n",
    "df.to_csv(\"BM.csv\", index=False)\n",
    "print(\"Dati salvati in BM.csv\")\n",
    "\n",
    "df = pd.read_csv(\"BM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results of BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(df['iteration'], df['kl_history'], marker='o', label='KL Divergence')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"KL Divergence\")\n",
    "plt.title(\"BM Training (Exact)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Quantum Boltzmann Machine, binary spin variables are replaced with (2^N x 2^N) matrices (operators), where N is now the number of quantum bits. The energy function (the model) is therefore replaced with a (2^N x 2^N) Hamiltonian matrix. The Hamiltonian is build in such a way that its diagonal elements correspond to classical energy values for each of the 2^N possible classical states. \n",
    "\n",
    "In this fully visible model, each parameter is associated with a (2^N x 2^N) matrix, and gamma is also a parameter to learn, but it is fixed to be the same for each non-diagonal (2^N x 2^N) matrix rapresenting transverse components of spin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Define Parameters\n",
    "N = 8  # Number of visible qubits\n",
    "M = 8  # Number of modes for data distribution\n",
    "p = 0.9  # Spin alignment probability with mode centers\n",
    "eta = 0.4 # Learning rate (increased)\n",
    "iterations = 35  # Number of optimization steps\n",
    "\n",
    "# Pauli Matrices\n",
    "I = np.array([[1, 0], [0, 1]])\n",
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "# Generate M random center points s^k in {+1, -1}^N\n",
    "centers = np.random.randint(low=0, high=2, size=(M, N)) # in {0,1}\n",
    "centers = 2*centers - 1  # map to {+1,-1}\n",
    "\n",
    "def mixture_data_distribution(all_states, centers, p):  \n",
    "    \"\"\"Generate training data as a mixture of M modes using \n",
    "        Bernouilli distribution: p^(N-d_kv)*(1-p)^d_kv \"\"\"\n",
    "    num_modes = centers.shape[0]  # The number of modes (M=8) is the centers' number of rows\n",
    "    N_ = centers.shape[1]         # The number of bits (N=10) is the centers' number of columns \n",
    "    N_states = all_states.shape[0] # (2^N)\n",
    "    probs = np.zeros(N_states, dtype=np.float32)\n",
    "    for s in range(N_states):  \n",
    "        mode_sum = 0.0\n",
    "        for k in range(num_modes): \n",
    "            d_ks = 0.5 * np.sum(1 - all_states[s, :] * centers[k, :])  # Hamming distance between state s and center k\n",
    "            mode_sum += p**(N_ - d_ks) * (1 - p)**d_ks  # mixture of Bernoulli distribution\n",
    "        probs[s] = mode_sum / num_modes   # Generating P_data for each state\n",
    "    # normalitation\n",
    "    probs /= probs.sum()\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tensor_product(ops):\n",
    "    \"\"\"Compute the tensor product of multiple operators.\"\"\"\n",
    "    result = ops[0]\n",
    "    for op in ops[1:]:\n",
    "        result = np.kron(result, op)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We report that while trying to speed-up the code we tried to compute the function 'tensor_product' using NUMBA. Unfortunately this didn't seem to make the computation faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def tensor_product(ops):\n",
    "    \"\"\"Compute the tensor product of multiple operators.\"\"\"\n",
    "    result = ops[0]\n",
    "    for op in ops[1:]:\n",
    "        result = np.kron(result, op)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the efficiency of the code we computed the (2^N x 2^N) matrices, representing spin operators, only once out of the 'for loops'. This did make the runtime faster: about 5 times faster than creating spin matrices in each cycle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma_z(a), sigma_x(a) and sigma_z(a,b) matrices for each a,b = 1,...,N\n",
    "gamma_sigma = np.zeros((2**N, 2**N))\n",
    "b_sigma = np.zeros(N, dtype=object)\n",
    "W_sigma = np.zeros((N, N),dtype=object)\n",
    "for a in range(N):\n",
    "    gamma_sigma += tensor_product([I] * a + [sigma_x] + [I] * (N - a - 1))\n",
    "    b_sigma[a] = tensor_product([I] * a + [sigma_z] + [I] * (N - a - 1)) \n",
    "    for b in range(a + 1, N): \n",
    "        W_sigma[a,b] = tensor_product([I] * a + [sigma_z] + [I] * (b - a - 1) + [sigma_z] + [I] * (N - b - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_states(N):\n",
    "    all_states = np.zeros((2**N, N))\n",
    "    for s in range(N):\n",
    "        all_states[:, s] = np.diag(b_sigma[s])  # each state is a diagonal element of the sigma_z(a) matrices \n",
    "    return all_states\n",
    "\n",
    "def build_hamiltonian(N, Gamma, b, W):\n",
    "    \"\"\"Construct the Fully Visible QBM Hamiltonian with a transverse field.\"\"\"\n",
    "    H = np.zeros((2**N, 2**N), dtype=complex) # Size (2^N, 2^N)\n",
    "    H = -Gamma * gamma_sigma  # Transverse field\n",
    "    H -= np.dot(b, b_sigma) \n",
    "    H -= np.sum(W * W_sigma, axis=None) \n",
    "    return H\n",
    "\n",
    "def compute_density_matrix(H):\n",
    "    \"\"\"Compute the density matrix rho = e^(-H)/Z\"\"\"\n",
    "    exp_H = expm(-H)  # exp(-H)\n",
    "    Z = np.trace(exp_H)\n",
    "    return exp_H / Z, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again trying to speed up the alogirthm, we computed the exponential of the matrix H approximatevely. Even with a very few order of approsimization (n=2), this did make the code a little faster, but it still didn't allow computation for bigger N. Therefore, we ended up using the numpy function 'expm()' in the final results. \n",
    "\n",
    "Note: We tried to use Numba for this function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation of matrix exponentiation\n",
    "def matrix_exponential_approx(A, n_terms=2):\n",
    "    result = np.eye(A.shape[0])\n",
    "    term = np.eye(A.shape[0]) \n",
    "    for i in range(1, n_terms + 1):\n",
    "        term = np.dot(term, A) / i  \n",
    "        result += term  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_full_probability_distribution(rho):\n",
    "    \"\"\"Return the diagonal elements of rho as the model probability distribution.\"\"\"\n",
    "    return np.real(np.diag(rho))\n",
    "\n",
    "# Kullback-Leibler (KL) divergence: KL = Likelihood - Likelihood_min\n",
    "def compute_kl_upper_bound(P_data, P_model):\n",
    "    \"\"\"Compute the KL divergence upper bound using P_model: diagonal elements of rho.\"\"\"\n",
    "    return np.sum(P_data * np.log((P_data + 1e-12)/(P_model + 1e-12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the QBM fuly visible model, the gradient steps for each parameter are obtained by computing the difference of the expetation value of the derivative of the matrix exp(-H) projected on a visible state, averaged over the actual data distribution of all states, and the expectation value of the respective operator matrix (Boltzmann averaging). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building derivative to compute \"positive phase\"\n",
    "def compute_partial_expH(H, rho, Z, projector, partial_H, n):\n",
    "   avg_v = 0.0\n",
    "   delta_t = 1.0 / n\n",
    "   trace = np.trace(projector @ (rho * Z))\n",
    "   exp_tH = expm(-delta_t * H) # we compute only once exp_th in order to optimize efficiency\n",
    "   exp1 = np.eye(H.shape[0])\n",
    "   for m in range(1, n + 1):\n",
    "      t = m * delta_t\n",
    "      exp1 = exp1 @ exp_tH  # e^(-τH)\n",
    "      exp2 = expm((t - 1) * H) # e^{-(1-τ)H}\n",
    "      avg_v += np.trace(projector @ exp1 @ partial_H @ exp2) / (trace + 1e-12) * delta_t\n",
    "   return -avg_v\n",
    "\n",
    "# Compute \"positive\" and \"negative phase\" averages: <sigma_z_a>, <sigma_z_a sigma_z_b> for each a,b = 1,2,...,N\n",
    "\n",
    "state_proj = np.zeros((2**N, 2**N))\n",
    "\n",
    "def compute_gradient_update(P_data, H, rho, Z, all_states, N, eta):\n",
    "    \"\"\"Compute the gradient updates for the QBM parameters.\"\"\"\n",
    "    n = 2   # To allow computation we kept at minimum the iteration steps of the 'compute_partial_expH' function\n",
    "    global state_proj\n",
    "\n",
    "    z_model_avg = np.zeros(N)\n",
    "    zz_model_avg = np.zeros((N, N))\n",
    "    z_data_avg = np.zeros(N)\n",
    "    zz_data_avg = np.zeros((N, N)) \n",
    "\n",
    "    N_states = all_states.shape[0]\n",
    "    partial_expH_Gamma = np.zeros(N_states)\n",
    "    for z in range(N_states):\n",
    "        state_proj[z, z] = 1\n",
    "        partial_expH_Gamma[z] = compute_partial_expH(H, rho, Z, state_proj, gamma_sigma, n)\n",
    "        state_proj[z, z] = 0\n",
    "\n",
    "    for a in range(N):\n",
    "      z_model_avg[a] = np.trace(rho @ b_sigma[a]).real\n",
    "      Gamma_data_avg = 0.\n",
    "      for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            z_data_avg[a] += P_data[z] * compute_partial_expH(H, rho, Z, state_proj, b_sigma[a], n)\n",
    "            Gamma_data_avg += P_data[z] * partial_expH_Gamma[z]\n",
    "            state_proj[z, z] = 0\n",
    "      for b in range(a + 1, N):\n",
    "         zz_model_avg[a, b] = np.trace(rho @  W_sigma[a,b]).real\n",
    "         #zz_model_avg[b, a] = zz_model_avg[a, b]  # Ensure symmetry\n",
    "         for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            zz_data_avg[a, b] += P_data[z] * compute_partial_expH(H, rho, Z, state_proj,  W_sigma[a, b], n)\n",
    "            #zz_data_avg[b, a] = zz_data_avg[a, b]  \n",
    "            state_proj[z, z] = 0\n",
    "             \n",
    "    Gamma_model_avg = np.trace(rho @ gamma_sigma).real\n",
    "\n",
    "    # Compute gradient steps as difference between positive and negative phases\n",
    "    delta_b = -eta * (z_data_avg + z_model_avg)\n",
    "    delta_W = -eta * (zz_data_avg + zz_model_avg)\n",
    "    delta_Gamma = -eta * (Gamma_data_avg + Gamma_model_avg)\n",
    "\n",
    "    return delta_b, delta_W, delta_Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last attempt to speed-up the computation, to be able to compute the machine learning algorithm for bigger number of qubits N, was to substitute the function 'compute_partial_expH' with a Fortran function that computed the same derivative. Analizying the code we noticed that this one was the computationally most demanding function and removing it would allow the algorithm to run for N=10. Indeed this function was the main and only difference from the b-QBM algorithm which did run for bigger N (N=10).\n",
    "We implemented a Fortran test function that only computed a trace of a matrix (H) to verify the speed-up. The test was run with N=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fortran test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subroutine test(A, N, avg)\n",
    "\n",
    "    integer, intent(in) :: N\n",
    "\n",
    "    real, dimension(1024, 1024), intent(in) :: A\n",
    "\n",
    "    real, intent(out) :: avg\n",
    "    \n",
    "    integer :: i\n",
    "\n",
    "    avg=0.\n",
    "    do i = 1, 2**N\n",
    "      avg = avg + A(i,i)\n",
    "    end do\n",
    "end subroutine test\n",
    "\n",
    "#Note: 'python3 -m numpy.f2py -c -m  test  test.f90' to compile the Fortran f2py module to be able to import it in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/filepath')\n",
    "import test\n",
    "\n",
    "N=10\n",
    "state_proj = np.zeros((2**N, 2**N))\n",
    "\n",
    "def compute_gradient_update(P_data, H, rho, Z, all_states, N, eta):\n",
    "    \"\"\"Compute the gradient updates for the QBM parameters.\"\"\"\n",
    "    global state_proj\n",
    "\n",
    "    z_model_avg = np.zeros(N)\n",
    "    zz_model_avg = np.zeros((N, N))\n",
    "    z_data_avg = np.zeros(N)\n",
    "    zz_data_avg = np.zeros((N, N)) \n",
    "\n",
    "    N_states = all_states.shape[0]\n",
    "    partial_expH_Gamma = np.zeros(N_states)\n",
    "    for z in range(N_states):\n",
    "        state_proj[z, z] = 1\n",
    "        partial_expH_Gamma[z] = test.test(H, N)\n",
    "        state_proj[z, z] = 0\n",
    "\n",
    "    for a in range(N):\n",
    "      z_model_avg[a] = np.trace(rho @ b_sigma[a]).real\n",
    "      Gamma_data_avg = 0.\n",
    "      for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            z_data_avg[a] += P_data[z] * test.test(H, N)\n",
    "            Gamma_data_avg += P_data[z] * partial_expH_Gamma[z]\n",
    "            state_proj[z, z] = 0\n",
    "      for b in range(a + 1, N):\n",
    "         zz_model_avg[a, b] = np.trace(rho @  W_sigma[a,b]).real\n",
    "         #zz_model_avg[b, a] = zz_model_avg[a, b]  # Ensure symmetry\n",
    "         for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            zz_data_avg[a, b] += P_data[z] * test.test(H, N)\n",
    "            #zz_data_avg[b, a] = zz_data_avg[a, b]  \n",
    "            state_proj[z, z] = 0\n",
    "             \n",
    "    Gamma_model_avg = np.trace(rho @ gamma_sigma).real\n",
    "\n",
    "    # Compute gradient steps as difference between positive and negative phases\n",
    "    delta_b = -eta * (z_data_avg + z_model_avg)\n",
    "    delta_W = -eta * (zz_data_avg + zz_model_avg)\n",
    "    delta_Gamma = -eta * (Gamma_data_avg + Gamma_model_avg)\n",
    "\n",
    "    return delta_b, delta_W, delta_Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then computed the same test function using numpy, as before we tested it with N=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(H):\n",
    "    avg = np.trace(H)\n",
    "    return avg\n",
    "\n",
    "N=10\n",
    "state_proj = np.zeros((2**N, 2**N))\n",
    "\n",
    "def compute_gradient_update(P_data, H, rho, Z, all_states, N, eta):\n",
    "    \"\"\"Compute the gradient updates for the QBM parameters.\"\"\"\n",
    "    global state_proj\n",
    "\n",
    "    z_model_avg = np.zeros(N)\n",
    "    zz_model_avg = np.zeros((N, N))\n",
    "    z_data_avg = np.zeros(N)\n",
    "    zz_data_avg = np.zeros((N, N)) \n",
    "\n",
    "    N_states = all_states.shape[0]\n",
    "    partial_expH_Gamma = np.zeros(N_states)\n",
    "    for z in range(N_states):\n",
    "        state_proj[z, z] = 1\n",
    "        partial_expH_Gamma[z] = test(H)\n",
    "        state_proj[z, z] = 0\n",
    "\n",
    "    for a in range(N):\n",
    "      z_model_avg[a] = np.trace(rho @ b_sigma[a]).real\n",
    "      Gamma_data_avg = 0.\n",
    "      for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            z_data_avg[a] += P_data[z] * test(H)\n",
    "            Gamma_data_avg += P_data[z] * partial_expH_Gamma[z]\n",
    "            state_proj[z, z] = 0\n",
    "      for b in range(a + 1, N):\n",
    "         zz_model_avg[a, b] = np.trace(rho @  W_sigma[a,b]).real\n",
    "         #zz_model_avg[b, a] = zz_model_avg[a, b]  # Ensure symmetry\n",
    "         for z in range(N_states):\n",
    "            state_proj[z, z] = 1\n",
    "            zz_data_avg[a, b] += P_data[z] * test(H)\n",
    "            #zz_data_avg[b, a] = zz_data_avg[a, b]  \n",
    "            state_proj[z, z] = 0\n",
    "             \n",
    "    Gamma_model_avg = np.trace(rho @ gamma_sigma).real\n",
    "\n",
    "    # Compute gradient steps as difference between positive and negative phases\n",
    "    delta_b = -eta * (z_data_avg + z_model_avg)\n",
    "    delta_W = -eta * (zz_data_avg + zz_model_avg)\n",
    "    delta_Gamma = -eta * (Gamma_data_avg + Gamma_model_avg)\n",
    "\n",
    "    return delta_b, delta_W, delta_Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the runtime was slower with the Fortran function. This led us to abandon the implementation with Fortran.\n",
    "\n",
    "![Python test](Python_test_runtime.jpeg)\n",
    "![Fortran test](Fortran_test_runtime.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qbm(P_data, all_states, N, Gamma, b, W, eta, iterations):\n",
    "    \"\"\"Optimize the Fully Visible Bound-Based QBM.\"\"\"\n",
    "\n",
    "    kl_divergence = []\n",
    "    for it in range(iterations):\n",
    "        H = build_hamiltonian(N, Gamma, b, W)\n",
    "        rho,_ = compute_density_matrix(H)\n",
    "        _,Z = compute_density_matrix(H)\n",
    "\n",
    "        # Compute model distribution\n",
    "        P_model = compute_full_probability_distribution(rho)\n",
    "\n",
    "        # Compute and save KL value\n",
    "        KL_bound = compute_kl_upper_bound(P_data, P_model)\n",
    "        kl_divergence.append(KL_bound)\n",
    "        \n",
    "        delta_b, delta_W, delta_Gamma = compute_gradient_update(P_data, H, rho, Z, all_states, N, eta)\n",
    "        b += delta_b\n",
    "        W += delta_W\n",
    "        Gamma += delta_Gamma\n",
    "\n",
    "        print(f\"Iteration {it+1}/{iterations}, KL Divergence: {KL_bound:.6f}, Δb={np.linalg.norm(delta_b):.6f}, Δw={np.linalg.norm(delta_W):.6f}\")\n",
    "    return kl_divergence\n",
    "\n",
    "# Initialize parameters (b, W, Gamma) using 'random.seed'\n",
    "np.random.seed(42)\n",
    "b = 0.1 * np.random.randn(N)\n",
    "W = 0.1 * np.random.randn(N, N)\n",
    "Gamma = 0.1 * np.random.rand()\n",
    "\n",
    "all_states = build_states(N)\n",
    "P_data = mixture_data_distribution(all_states, centers, p)\n",
    "print(\"Check sum of P_data:\", P_data.sum().item())  # ~1.0\n",
    "print(\"Check dimension of P_data:\", P_data.shape)  # ~2^10 = 1024\n",
    "print(type(P_data))\n",
    "\n",
    "# Optimize the Fully Visible QBM\n",
    "kl_divergence = optimize_qbm(P_data, all_states, N, Gamma, b, W, eta, iterations)\n",
    "\n",
    "# Saving Data frame in CSV\n",
    "df = pd.DataFrame({\"iteration\": range(1, iterations + 1), \"kl_divergence\": kl_divergence})\n",
    "df.to_csv(\"FullyVisible_QBM.csv\", index=False)\n",
    "print(\"Dati salvati in FullyVisible_QBM.csv\")\n",
    "\n",
    "df = pd.read_csv(\"FullyVisible_QBM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results of QBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot KL divergence upper bound over iterations\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(df['iteration'], df['kl_divergence'], marker='o', label='KL divergence over Iterations')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"KL divergence\")\n",
    "plt.title(\"KL divergence Over Iterations (FV-QBM)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bound - Quantum Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Define Parameters\n",
    "N = 8  # Number of visible qubits\n",
    "M = 8  # Number of modes for data distribution\n",
    "p = 0.9  # Spin alignment probability with mode centers\n",
    "eta = 0.9 # Learning rate (increased)\n",
    "iterations = 35  # Number of optimization steps\n",
    "Gamma = 2 # Fixed transverse field strength\n",
    "\n",
    "# Pauli Matrices\n",
    "I = np.array([[1, 0], [0, 1]])\n",
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "# Generate M random center points s^k in {+1, -1}^N\n",
    "centers = np.random.randint(low=0, high=2, size=(M, N)) # in {0,1}\n",
    "centers = 2*centers - 1  # map to {+1,-1}\n",
    "\n",
    "def mixture_data_distribution(all_states, centers, p):  \n",
    "    \"\"\"Generate training data as a mixture of M modes using \n",
    "        Bernouilli distribution: p^(N-d_kv)*(1-p)^d_kv \"\"\"\n",
    "    num_modes = centers.shape[0]  # The number of modes (M=8) is the centers' number of rows\n",
    "    N_ = centers.shape[1]         # The number of bits (N=10) is the centers' number of columns \n",
    "    N_states = all_states.shape[0] # (2^N)\n",
    "    probs = np.zeros(N_states, dtype=np.float32)\n",
    "    for s in range(N_states):  \n",
    "        mode_sum = 0.0\n",
    "        for k in range(num_modes): \n",
    "            d_ks = 0.5 * np.sum(1 - all_states[s, :] * centers[k, :])  # Hamming distance between state s and center k\n",
    "            mode_sum += p**(N_ - d_ks) * (1 - p)**d_ks  # mixture of Bernoulli distribution\n",
    "        probs[s] = mode_sum / num_modes   # Generating P_data for each state\n",
    "    # normalitation\n",
    "    probs /= probs.sum()\n",
    "    return probs\n",
    "\n",
    "def tensor_product(ops):\n",
    "    \"\"\"Compute the tensor product of multiple operators.\"\"\"\n",
    "    result = ops[0]\n",
    "    for op in ops[1:]:\n",
    "        result = np.kron(result, op)\n",
    "    return result\n",
    "\n",
    "# Compute sigma_z(a), sigma_x(a) and sigma_z(a,b) matrices for each a,b = 1,...,N\n",
    "b_sigma = np.zeros(N, dtype=object)\n",
    "gamma_sigma = np.zeros((2**N, 2**N))\n",
    "W_sigma = np.zeros((N, N),dtype=object)\n",
    "for a in range(N):\n",
    "    gamma_sigma += tensor_product([I] * a + [sigma_x] + [I] * (N - a - 1))\n",
    "    b_sigma[a] = tensor_product([I] * a + [sigma_z] + [I] * (N - a - 1)) \n",
    "    for b in range(a + 1, N): \n",
    "        W_sigma[a, b] = tensor_product([I] * a + [sigma_z] + [I] * (b - a - 1) + [sigma_z] + [I] * (N - b - 1))\n",
    "\n",
    "def build_states(N):\n",
    "    all_states = np.zeros((2**N, N))\n",
    "    for s in range(N):\n",
    "        all_states[:, s] = np.diag(b_sigma[s])  # each state is a diagonal element of the sigma_z(a) matrices \n",
    "    return all_states\n",
    "\n",
    "def build_hamiltonian(N, Gamma, b, W):\n",
    "    \"\"\"Construct the Fully Visible QBM Hamiltonian with a transverse field.\"\"\"\n",
    "    H = np.zeros((2**N, 2**N), dtype=complex) # Size (2^N, 2^N)\n",
    "    H = -Gamma * gamma_sigma  # Transverse field\n",
    "    H -= np.dot(b, b_sigma)  \n",
    "    H -= np.sum(W * W_sigma, axis=None)  \n",
    "    return H\n",
    "\n",
    "def compute_density_matrix(H):\n",
    "    \"\"\"Compute the density matrix rho = exp(-H) / Z.\"\"\"\n",
    "    exp_H = expm(-H)\n",
    "    Z = np.trace(exp_H)\n",
    "    rho = exp_H / Z\n",
    "    return rho, Z\n",
    "\n",
    "def compute_full_probability_distribution(rho):\n",
    "    \"\"\"Compute the full probability distribution P_v from diagonal elements of rho.\"\"\"\n",
    "    return np.real(np.diag(rho))  # Extract diagonal elements as probabilities\n",
    "\n",
    "# Kullback-Leibler (KL) divergence: KL = Likelihood - Likelihood_min\n",
    "def compute_kl_upper_bound(P_data, P_model):\n",
    "    \"\"\"Compute the KL divergence upper bound using P_model: diagonal elements of rho.\"\"\"\n",
    "    return np.sum(P_data * np.log((P_data + 1e-12)/(P_model + 1e-12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute \"positive\" and \"negative phase\" averages: <sigma_z_a>, <sigma_z_a sigma_z_b> for each a,b = 1,2,...,N\n",
    "def compute_gradient_update(P_data, rho, all_states, N, eta):\n",
    "    \"\"\"Compute gradient updates for b and w.\"\"\"\n",
    "\n",
    "    z_model_avg = np.zeros(N)\n",
    "    zz_model_avg = np.zeros((N, N))\n",
    "    z_data_avg = np.zeros(N)\n",
    "    zz_data_avg = np.zeros((N, N))\n",
    "\n",
    "    # Negative phase\n",
    "    N_states = all_states.shape[0]\n",
    "    for a in range(N):\n",
    "      z_model_avg[a] = np.trace(rho @ b_sigma[a]).real\n",
    "      for b in range(a + 1, N):\n",
    "         zz_model_avg[a, b] = np.trace(rho @ W_sigma[a, b]).real\n",
    "         #zz_model_avg[b, a] = zz_model_avg[a, b]\n",
    "    \n",
    "    # Positive phase\n",
    "    N_states = all_states.shape[0]\n",
    "    for i in range(N_states):\n",
    "        z_data_avg += P_data[i] * all_states[i, :]\n",
    "        zz_data_avg += P_data[i] * np.outer(all_states[i, :], all_states[i, :])\n",
    "\n",
    "    # Compute gradient steps as difference between positive and negative phases\n",
    "    delta_b = eta * (z_data_avg - z_model_avg)\n",
    "    delta_W = eta * (zz_data_avg - zz_model_avg)\n",
    "    return delta_b, delta_W\n",
    "\n",
    "def optimize_qbm(P_data, all_states, N, Gamma, b, W, eta, iterations):\n",
    "    \"\"\"Optimize the Fully Visible Bound-Based QBM.\"\"\"\n",
    "\n",
    "    kl_upper_bounds = []\n",
    "    for it in range(iterations):\n",
    "        H = build_hamiltonian(N, Gamma, b, W)\n",
    "        rho, _ = compute_density_matrix(H)\n",
    "\n",
    "        # Compute model distribution\n",
    "        P_model = compute_full_probability_distribution(rho)\n",
    "        \n",
    "        # Compute and save KL value\n",
    "        KL_bound = compute_kl_upper_bound(P_data, P_model)\n",
    "        kl_upper_bounds.append(KL_bound)\n",
    "        \n",
    "        delta_b, delta_W = compute_gradient_update(P_data, rho, all_states, N, eta)\n",
    "        b += delta_b\n",
    "        W += delta_W\n",
    "\n",
    "        print(f\"Iteration {it+1}/{iterations}, KL Upper Bound: {KL_bound:.6f}, Δb={np.linalg.norm(delta_b):.6f}, Δw={np.linalg.norm(delta_W):.6f}\")\n",
    "    return kl_upper_bounds\n",
    "\n",
    "# Initialize parameters (b, W) using 'random.seed'\n",
    "np.random.seed(42)\n",
    "b = 0.01 * np.random.randn(N)\n",
    "W = 0.01 * np.random.randn(N, N)\n",
    "\n",
    "all_states = build_states(N)\n",
    "P_data = mixture_data_distribution(all_states, centers, p)\n",
    "print(\"Check sum of P_data:\", P_data.sum().item())  # ~1.0\n",
    "print(\"Check dimension of P_data:\", P_data.shape)  # ~2^10 = 1024\n",
    "print(type(P_data))\n",
    "\n",
    "# Optimize the Fully Visible Bound-Based QBM\n",
    "kl_upper_bounds = optimize_qbm(P_data, all_states, N, Gamma, b, W, eta, iterations)\n",
    "\n",
    "# Saving Data frame in CSV\n",
    "df = pd.DataFrame({\"iteration\": range(1, iterations + 1), \"kl_upper_bounds\": kl_upper_bounds})\n",
    "df.to_csv(\"FullyVisible_bQBM.csv\", index=False)\n",
    "print(\"Dati salvati in FullyVisible_bQBM.csv\")\n",
    "\n",
    "df = pd.read_csv(\"FullyVisible_bQBM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results of b-QBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot KL divergence upper bound over iterations\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(df['iteration'], df['kl_upper_bounds'], marker='o', label='KL Upper Bound over Iterations')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"KL Upper Bound\")\n",
    "plt.title(\"KL Upper Bound Over Iterations (FV-bQBM)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results of BM, QBM and b-QBM all together for a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = \"/Users/andreadecristofaro/BM.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "plt.plot(df['iteration'], df['kl_history'], marker='o', color='green', label='BM_N=8')\n",
    "\n",
    "file_path = \"/Users/andreadecristofaro/FullyVisible_bQBM.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "plt.plot(df['iteration'], df['kl_upper_bounds'], marker='o', color='red', label='bQBM_N=8')\n",
    "\n",
    "file_path = \"/Users/andreadecristofaro/FullyVisible_QBM.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "plt.plot(df['iteration'], df['kl_divergence'], marker='o', color='blue', label='QBM_N=8')\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"KL\")\n",
    "plt.title(\"KL divergence Over Iterations\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
